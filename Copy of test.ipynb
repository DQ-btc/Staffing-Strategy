{"cells":[{"cell_type":"markdown","metadata":{"id":"73eaf3be"},"source":["# Dynamic Staffing Optimization for Advertiser Support\n","\n","This notebook implements a full solution for dynamically planning agent staffing in 2025. We combine:\n","\n","- A (dummy) forecast of eligible advertiser sign-ups per month (using historical data as an example).\n","- A dynamic programming (DP) formulation inspired by supply chain inventory management that decides, month-by-month, how many agents to hire or fire.\n","\n","The DP balances the revenue uplift from serving advertisers against the cost of idle capacity, unmet demand, and firing agents (with associated firing costs).\n","\n","Each agent can support up to 10 advertisers, and new hires require a 1-month ramp-up (i.e. they are only effective in the following month)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0bdb0df4","executionInfo":{"status":"ok","timestamp":1740648170484,"user_tz":480,"elapsed":1313,"user":{"displayName":"Tianyu Qi","userId":"17826089204286335850"}},"outputId":"bb8d69ad-90d3-4bdb-c0d5-377186ed3bb3","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["Forecast for USA (eligible sign-ups):\n","2025-01 : 20\n","2025-02 : 25\n","2025-03 : 30\n","2025-04 : 28\n","2025-05 : 22\n","2025-06 : 35\n","2025-07 : 40\n","2025-08 : 38\n","2025-09 : 32\n","2025-10 : 30\n","2025-11 : 27\n","2025-12 : 25\n"]}],"source":["# Import required libraries\n","import pandas as pd\n","import numpy as np\n","\n","# For demonstration purposes, we create a dummy forecast for eligible advertiser sign-ups.\n","simulation_months = pd.date_range(start='2025-01-01', end='2025-12-01', freq='MS')\n","\n","# Dummy forecast data for USA (number of eligible sign-ups per month)\n","forecast_usa = [20, 25, 30, 28, 22, 35, 40, 38, 32, 30, 27, 25]\n","\n","print(\"Forecast for USA (eligible sign-ups):\")\n","for m, d in zip(simulation_months, forecast_usa):\n","    print(m.strftime('%Y-%m'), \":\", d)"]},{"cell_type":"markdown","metadata":{"id":"f0aa1093"},"source":["## Dynamic Programming Formulation\n","\n","We now model the staffing decision as a DP problem. Consider the following:\n","\n","- **State:** \\( I_t \\) = number of active agents (each with capacity 10) in month \\( t \\).\n","- **Decisions:** In month \\( t \\), decide how many agents to hire (\\( h_t \\)) and fire (\\( f_t \\)). Note that hires become effective only in the following month.\n","- **Immediate Reward:**\n","  - **Revenue:** We earn \\( r \\) per advertiser served (up to a capacity of \\( 10 \\times I_t \\)).\n","  - **Idle Cost:** If capacity exceeds demand \\( D_t \\), we incur a cost \\( c_{idle} \\) per unused capacity unit.\n","  - **Shortage Cost:** If capacity is insufficient, we incur a penalty \\( c_{short} \\) per unmet capacity unit.\n","  - **Firing Cost:** Firing an agent costs a fixed amount.\n","\n","The state transition for month \\( t+1 \\) is:\n","\n"," \\( I_{t+1} = I_t - f_t + h_t \\)\n","\n","The DP recursion is then:\n","\n"," \\( V(t, I_t) = \\max_{h_t, f_t}\\{ R_t(I_t, D_t) - (\\text{firing cost}) + V(t+1, I_t - f_t + h_t) \\} \\)\n","\n","with the terminal condition \\( V(T+1, I) = 0 \\)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6d0f8467","executionInfo":{"status":"ok","timestamp":1740648182641,"user_tz":480,"elapsed":83,"user":{"displayName":"Tianyu Qi","userId":"17826089204286335850"}},"outputId":"ffcf5e2f-6f66-444f-b463-fd5230bae9ed","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["Optimal cumulative net reward: 33960.0\n","\n","Optimal Decisions (month, active_agents, (hires, fires)):\n","(1, 5, (0, 0))\n","(2, 5, (0, 0))\n","(3, 5, (0, 0))\n","(4, 5, (0, 0))\n","(5, 5, (0, 0))\n","(6, 5, (0, 0))\n","(7, 5, (0, 0))\n","(8, 5, (0, 0))\n","(9, 5, (0, 0))\n","(10, 5, (0, 0))\n","(11, 5, (0, 0))\n","(12, 5, (0, 0))\n"]}],"source":["# Define parameters for the DP and cost functions\n","params = {\n","    'T': 12,                       # Total months (2025)\n","    'agent_capacity': 10,          # Each agent supports 10 advertisers\n","    'r': 100,                      # Revenue per advertiser served\n","    'c_idle': 5,                   # Idle cost per unused capacity unit\n","    'c_short': 20,                 # Shortage cost per unmet capacity unit\n","    'max_hire': 5,                 # Maximum agents that can be hired in one month\n","    'annual_salary': 80000,\n","    # Firing cost: 40% of annual salary prorated monthly\n","    'firing_cost': 0.4 * 80000 / 12\n","}\n","\n","def compute_immediate_reward(I, D, params):\n","    \"\"\"\n","    Compute immediate reward for a month given current active agents I and demand D.\n","\n","    - Capacity = I * (agent capacity)\n","    - Revenue = r * min(capacity, D)\n","    - Idle cost = c_idle * max(capacity - D, 0)\n","    - Shortage cost = c_short * max(D - capacity, 0)\n","    \"\"\"\n","    capacity = I * params['agent_capacity']\n","    served = min(capacity, D)\n","    revenue = params['r'] * served\n","    idle_cost = params['c_idle'] * max(capacity - D, 0)\n","    shortage_cost = params['c_short'] * max(D - capacity, 0)\n","    return revenue - idle_cost - shortage_cost\n","\n","def dp(t, I, forecast, params, memo, decision):\n","    \"\"\"\n","    Recursive DP function that computes the maximum cumulative net reward from month t to T,\n","    given I active agents at the start of month t.\n","\n","    - forecast: list of demand values (number of eligible advertiser sign-ups) for each month t (1-indexed)\n","    - I: current active agents (each agent has a capacity of 10)\n","    - h (hires) and f (fires) are the decisions for month t; note that hires become active in the next month.\n","    \"\"\"\n","    T = params['T']\n","    if t > T:\n","        return 0  # Terminal condition: no reward after month T\n","\n","    if (t, I) in memo:\n","        return memo[(t, I)]\n","\n","    best_value = -np.inf\n","    best_decision = None\n","\n","    # Loop over possible hiring (h) and firing (f) decisions\n","    for h in range(params['max_hire'] + 1):\n","        for f in range(I + 1):  # you can fire up to I agents\n","            # Immediate reward is computed using current active agents I\n","            immediate_reward = compute_immediate_reward(I, forecast[t-1], params)\n","\n","            # Subtract firing cost (firing cost is incurred in the current month)\n","            immediate_reward -= f * params['firing_cost']\n","\n","            # Next month's state: agents = current agents - fired + hired\n","            I_next = I - f + h\n","\n","            # Recursively compute the future value\n","            future_value = dp(t + 1, I_next, forecast, params, memo, decision)\n","            total_value = immediate_reward + future_value\n","\n","            if total_value > best_value:\n","                best_value = total_value\n","                best_decision = (h, f)\n","\n","    memo[(t, I)] = best_value\n","    decision[(t, I)] = best_decision\n","    return best_value\n","\n","def reconstruct_decisions(t, I, forecast, params, decision):\n","    \"\"\"\n","    Reconstruct the optimal decision path starting from month t with I active agents.\n","    Returns a list of tuples: (month, active_agents, (hires, fires))\n","    \"\"\"\n","    T = params['T']\n","    decisions = []\n","    while t <= T:\n","        dec = decision.get((t, I), (0, 0))\n","        decisions.append((t, I, dec))\n","        h, f = dec\n","        I = I - f + h\n","        t += 1\n","    return decisions\n","\n","# Set forecast demand for USA using our dummy data\n","forecast = forecast_usa  # list of 12 values corresponding to months 1 to 12\n","\n","# Initial number of active agents (e.g., from agent_staffing.csv, assume 5 for USA)\n","initial_agents = 5\n","\n","# Run DP\n","memo = {}\n","decision = {}\n","optimal_value = dp(1, initial_agents, forecast, params, memo, decision)\n","\n","print(\"Optimal cumulative net reward:\", optimal_value)\n","\n","# Reconstruct and display the optimal decisions path\n","optimal_decisions = reconstruct_decisions(1, initial_agents, forecast, params, decision)\n","print(\"\\nOptimal Decisions (month, active_agents, (hires, fires)):\")\n","for d in optimal_decisions:\n","    print(d)"]},{"cell_type":"markdown","metadata":{"id":"e1a7c122"},"source":["## Summary\n","\n","In this notebook, we:\n","\n","1. **Forecasted** the number of eligible advertiser sign-ups for USA (dummy data).\n","2. **Formulated** a dynamic programming model where each month we decide how many agents to hire or fire.\n","3. **Optimized** the staffing plan to maximize net reward (revenues minus idle, shortage, and firing costs).\n","\n","You can adjust the forecast data, cost parameters, or constraints as needed for your analysis."]},{"cell_type":"code","source":["# prompt: Gurobi Linear\n","\n","import gurobipy as gp\n","from gurobipy import GRB\n","\n","# Define parameters (replace with your actual data)\n","# appear 30 days\n","appear_usa = []\n","initial_agents = 5  # Initial number of active agents\n","\n","# Fixed values\n","agent_capacity = 10\n","finish_period = 60 # days\n","ramp_up_period = 30 # days\n","\n","r = 100\n","c_idle = 5\n","c_short = 20\n","max_hire = 5\n","firing_cost = 0.4 * 80000 / 12\n","initial_agents = 5\n","\n","# Create a Gurobi model\n","model = gp.Model(\"StaffingOptimization\")\n","\n","# Decision variables\n","hires = [model.addVar(name=f\"hires_{t}\", lb=0, ub=max_hire, vtype=GRB.INTEGER) for t in range(T)]\n","fires = [model.addVar(name=f\"fires_{t}\", lb=0, vtype=GRB.INTEGER) for t in range(T)]\n","agents = [model.addVar(name=f\"agents_{t}\", lb=0, vtype=GRB.INTEGER) for t in range(T)]\n","served = [model.addVar(name=f\"served_{t}\", lb=0, vtype=GRB.INTEGER) for t in range(T)]\n","\n","# Initial condition\n","model.addConstr(agents[0] == initial_agents)\n","\n","\n","# Constraints\n","for t in range(T):\n","  # Agent balance\n","  if t > 0:\n","    model.addConstr(agents[t] == agents[t-1] - fires[t-1] + hires[t-1])\n","  # Capacity constraint\n","  model.addConstr(served[t] <= agents[t] * agent_capacity)\n","  model.addConstr(served[t] <= D[t])\n","\n","\n","# Objective function\n","obj = gp.quicksum(r * served[t] - c_idle * max(0, agents[t] * agent_capacity - D[t]) - c_short * max(0, D[t]- agents[t] * agent_capacity) - fires[t] * firing_cost for t in range(T))\n","model.setObjective(obj, GRB.MAXIMIZE)\n","\n","# Optimize the model\n","model.optimize()\n","\n","# Print the solution\n","print(\"\\nOptimal Solution:\")\n","if model.Status == GRB.OPTIMAL:\n","    for t in range(T):\n","        print(f\"Month {t+1}: Hires = {hires[t].x}, Fires = {fires[t].x}, Agents = {agents[t].x}, Served = {served[t].x}\")\n","\n","    print(f\"\\nOptimal objective value: {model.ObjVal}\")\n","else:\n","    print(\"No optimal solution found\")\n"],"metadata":{"id":"dBszrNlaOwMr"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.x"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}